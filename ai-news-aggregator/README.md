I am building a ai news aggregator where i can take multiple sources like youtube channels  and  blog posts from openai or something and scrap them and then  put it in a database where i have sources and all and i want to run a daily digest where it will take it and then it will give it to a llm summary as per the things of htat day and it will and based on the user insight that we specified as per teh agent syste prompt we can generate a daily digest with a small snippet with the link of the source and from the youtube channel i want to create a list of channels andwe want to get the latest video form the channels and using the api and for the blog post only url that we can scrap for that i want everything built in a python backend and use postgre db and use sqlalcemy for define models and create tables and project structure as per app folder and docker folder and where there will be basic setup for postgre and that is the starting point and later down the point we should bw able to put it on render and schedule it every 24 hours to run it so it will create a daily digest and it will send the email with my personaly daily digest.

https://openai.com/news/
https://www.anthropic.com/engineering
https://www.anthropic.com/research